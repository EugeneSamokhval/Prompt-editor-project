\section{Реализация платформы для интерактивного формирования запросов к языковым и генеративным нейросетям}

В данном разделе подробно описывается реализация программной платформы, предназначенной для интерактивного формирования запросов к современным языковым моделям и генеративным нейросетям. Целью разработки было создать удобный и гибкий инструмент, позволяющий пользователям составлять сложные запросы к моделям искусственного интеллекта (как текстовым, так и визуальным) в интерактивном режиме, используя наглядный интерфейс. Такой подход упрощает работу с крупными языковыми моделями и генеративными моделями изображений, скрывая сложность формулировки \textit{prompt}'ов \cite{lakera:2025} (текстовых запросов) и последовательной обработки данных.

Разрабатываемая платформа реализована по архитектуре клиент--сервер: \textbf{frontend} (клиентское веб-приложение) создан на основе Vue 3 с использованием хранилища состояний Pinia, а \textbf{backend} (серверная часть) реализован на фреймворке FastAPI на языке Python\cite{fastapi:practicum}. В качестве базы данных используется PostgreSQL с подключённым расширением pgvector для хранения и поиска векторных представлений данных. Данный стек технологий был выбран с учётом требований к интерактивности интерфейса, необходимости вызывать внешние API генеративных моделей, а также для обеспечения возможности масштабирования и расширения функциональности.

Ниже приводится структурированное описание архитектуры системы и ключевых компонентов реализации. Сначала рассматривается общая архитектура платформы и взаимодействие между её компонентами. Затем описывается клиентская часть, в том числе реализация drag-and-drop интерфейса для формирования запросов. После этого подробно изложена работа серверной части: обработка запросов, интеграция с внешними API (для генерации текстов и изображений) и использование векторного поиска для улучшения качества результатов. Завершает раздел \textbf{вывод} с описанием достигнутых результатов разработки и перспектив расширения системы.

\subsection{Архитектура платформы}

Разработанная платформа имеет многоуровневую архитектуру, разделяя функциональность между клиентской и серверной частями. На рис.~\ref{architecture} схематично представлено взаимодействие основных компонентов системы. Клиентское приложение предоставляет интерфейс пользователю для формирования запроса и визуализации результатов, в то время как серверное приложение отвечает за обработку этого запроса, взаимодействие с внешними сервисами (генеративными моделями) и доступ к базе данных. Такой подход соответствует принципам разделения ответственности и упрощает поддержку и модификацию системы.

Основные компоненты архитектуры:
\begin{enumerate}[label=\arabic*]
\item \textbf{Интерфейс пользователя (Frontend, Vue 3 + Pinia):} Одностраничное веб-приложение (single-page application), работающее в браузере. Отвечает за отображение элементов интерфейса, сбор ввода пользователя и интерактивное формирование запросов. Использование Vue 3 обеспечивает реактивность интерфейса и модульность кода, а Pinia используется для централизованного управления состоянием приложения (например, текущим набором элементов запроса, история запросов и результатов и др.)\cite{vuejs:wiki}.
\item \textbf{Сервер приложений (Backend, FastAPI):} Веб-сервер, реализующий API для обработки запросов от фронтенда. На сервере реализована бизнес-логика: получение структурированного запроса пользователя, его возможная предобработка (например, добавление контекста из базы знаний), вызов внешних API генеративных моделей для выполнения запроса (например, генерация текста или изображения), постобработка полученного результата и возврат ответа клиентскому приложению. Благодаря фреймворку FastAPI обеспечивается высокая производительность и поддержка асинхронной обработки, что особенно важно при параллельных запросах к внешним сервисам \cite{yandex:fastapi}.
\item \textbf{База данных (PostgreSQL + pgvector):} Хранилище данных, используемое платформой для сохранения необходимой информации. Реляционная СУБД PostgreSQL выбрана за её надёжность и масштабируемость, а расширение pgvector позволяет хранить эмбеддинги (векторные представления) текстовых данных и выполнять поиск по схожести этих векторов \cite{postgresql:wiki}. База данных может сохранять, например, историю диалогов, сгенерированные ответы, либо набор справочных данных (знаний), которые используются моделью для более осмысленных ответов. Посредством pgvector реализован семантический поиск: по входному запросу можно находить ближайшие по смыслу тексты и подставлять их в качестве контекста для языковой модели.
\item \textbf{Внешние AI-сервисы:} Генеративные модели, с которыми взаимодействует платформа, развернуты на внешних серверах и доступны через API. Для генерации текста используется модель DeepSeek R1 (предоставляемая через DeepSeek API)\cite{deepseek:docs}, а для генерации изображений --- модель диффузионного типа (Kandinsy) через соответствующий API\cite{sitelabs:kandinsky}. Оба типа моделей являются современными представителями генеративных нейросетей: DeepSeek R1 — крупная языковая модель с поддержкой диалога и глубокого рассуждения, Kandinsky — модель для синтеза изображений по текстовому описанию. Обращение к ним по API означает, что вычислительные ресурсы по генерации выделены на стороне сервиса, а наша платформа выступает как посредник, отправляющий запросы и получающий готовые результаты.
\end{enumerate}

Взаимодействие компонентов происходит по следующему сценарию. Пользователь посредством фронтенда формирует запрос (например, текстовое описание задачи или сцены для генерации изображения). При отправке запроса клиентское приложение собирает все необходимые данные (включая текстовые поля, выбранные опции, прикреплённые изображения или другие элементы) и отправляет их на сервер через HTTP-запрос к API. Серверная часть принимает запрос, анализирует его тип и содержимое: если требуется текстовая генерация, вызывается соответствующий метод, если генерация изображения — другой метод. Перед обращением к модели сервер может обратиться к базе знаний: например, выполнить векторный поиск по базе ранее сохранённых данных для нахождения дополнительного контекста (релевантных текстов) и объединить их с запросом пользователя. Затем сервер формирует запрос к внешнему API нужной модели (с учётом ключа доступа и формата, требуемого API), и ожидает ответа. Получив результат от модели (сгенерированный текст или изображение), сервер производит сохранение результата в базу (при необходимости) и возвращает результат клиенту. Фронтенд, получив ответ, отображает пользователю сгенерированный контент. В случае изображения оно выводится прямо на страницу, в случае текста — отображается в виде ответа ассистента. При этом интерфейс может позволять пользователю далее уточнять запрос (например, задать уточняющий вопрос или отредактировать сгенерированный результат и отправить повторно), образуя интерактивный цикл работы.

Подобная архитектура обеспечивает гибкость: компоненты чётко разделены, что даёт возможность модифицировать их независимо. Например, можно заменить модель генерации текста на другую, не затрагивая интерфейс, достаточно изменить вызов в серверной части. Или можно развивать фронтенд (добавлять новые элементы взаимодействия) без изменения логики генерации на сервере. Использование стандартных веб-технологий (HTTP API, JSON) для обмена данными между фронтендом и бэкендом обеспечивает совместимость и простоту отладки.

\subsection{Интерфейс с перетаскиванием элементов (Frontend на Vue 3 + Pinia)}

Клиентская часть платформы реализована как одностраничное приложение на Vue 3, что позволяет создать динамичный интерфейс, обновляющийся без полной перезагрузки страницы. Одной из ключевых задач фронтенда было обеспечить \textit{drag-and-drop} интерфейс для интерактивного составления запросов. Это означает, что пользователю предоставляется возможность добавлять, удалять и менять местами различные блоки запроса с помощью мыши, просто перетаскивая элементы на экране.

Для реализации drag-and-drop функциональности были использованы возможности HTML5 Drag and Drop API и компоненты Vue. В частности, элементы интерфейса, представляющие части запроса (например, фрагмент текста инструкции, блок для ввода вопроса, изображение-пример или параметры генерации), сделали перетаскиваемыми с помощью атрибутов \verb|draggable| и соответствующих обработчиков событий (\verb|dragstart|, \verb|dragover|, \verb|drop| и т.д.). Когда пользователь начинает перетаскивание элемента, приложение запоминает (через Pinia-хранилище) текущий переносимый объект. Когда происходит сброс (drop) элемента на новую позицию или область, обновляется состояние списка блоков запроса. Pinia отвечает за централизованное хранение структуры запроса: каждый блок может быть представлен объектом с полями, описывающими его тип (текст, изображение, параметр), содержимое (например, сам текст или ссылка на файл изображения) и, возможно, дополнительные настройки.

Благодаря реактивности Vue, обновление состояния Pinia автоматически приводит к перерисовке списка блоков на экране в новом порядке. Это даёт плавный пользовательский опыт при сборке запроса из блоков. Пользователь может, к примеру, перетащить в область запроса готовый шаблон подсказки (prompt template)\cite{copilotworks:promptgen} из библиотеки слева, затем добавить свои уточнения текстом, а затем перетянуть специальный блок, обозначающий место, куда будет подставлен результат другого запроса. Такой механизм особенно полезен для составления сложных запросов, например, когда требуется сгенерировать текст по определённому шаблону или выполнить несколько шагов генерации (сначала текст, потом на основе этого текста — изображение).

Стоит отметить, что Pinia значительно упростила реализацию управления состоянием по сравнению с классическим Vuex (Vue 2), благодаря более простому синтаксису и TypeScript-совместимости. Были созданы отдельные store (хранилища) Pinia для разных частей состояния приложения. Например, один store хранит текущий состав блоков запроса (их список и свойства), другой — историю предыдущих запросов и ответов, третий — настройки пользователя (выбранные модели генерации, параметры вроде температуры генерации текста, желаемого разрешения изображения и т.п.). Разделение на несколько хранилищ повышает модульность: логика по управлению историей отделена от логики формирования текущего запроса.

Ниже приведён упрощённый пример компонента Vue, реализующего область с перетаскиваемыми блоками запроса. В этом фрагменте кода показано, как можно выводить список блоков и обеспечивать их перетаскивание с помощью директивы \verb|v-for| и событий drag-and-drop:

\begin{lstlisting}[language=HTML]
       <div class="query-builder" @drop="onDrop" @dragover.prevent>
             <div class="query-block" v-for="(block, index) in blocks" :key="block.id" draggable="true" @dragstart="onDragStart(block, index)">
               <div v-if="block.type === 'text'"> {{ block.text }} </div> <div v-else-if="block.type === 'image'">
                <img :src="block.preview" alt="Image" /> </div> <div v-else-if="block.type === 'param'">
                 <span>{{ block.name }}: {{ block.value }}</span>
                </div>
                </div>
              </div>
\end{lstlisting}

\vspace{-0.5\baselineskip} 
В приведённом фрагменте шаблона Vue каждый элемент \verb|<div class="query-block">| представляет отдельный блок запроса, который может быть текстовым, изображением или блоком параметров. Атрибут \verb|draggable="true"| делает элемент перетаскиваемым. Обработчик \verb|@dragstart| привязан к методу \verb|onDragStart|, который сохраняет переносимый блок и его индекс. Обработчик \verb|@drop| на контейнере \verb|query-builder| вызывается, когда блок отпущен в новой позиции; внутри метода \verb|onDrop| происходит обновление порядка блоков в списке \verb|blocks|. Использование \verb|@dragover.prevent| необходимо, чтобы разрешить сброс элементов (по умолчанию браузер запрещает сброс для необработанных зон). Таким образом, этот компонент даёт возможность динамически менять состав и последовательность частей запроса.

Другой важной частью фронтенда является форма ввода и отображения результатов. Над областью сборки запроса размещены поля для ввода основного текста запроса пользователя, а также (опционально) для указания негативных подсказок (\textit{negative prompt} для генерации изображений, чтобы исключить нежелательные детали), выбора модели или пресета настроек. Рядом располагаются кнопки: "Сгенерировать текст", "Сгенерировать изображение" и т.п., в зависимости от выбранного типа задачи. После нажатия соответствующей кнопки собранная структура запроса отправляется на сервер.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{picture/interface-screenshot_1.png}
    \caption{Алгоритм оценки качества запроса}\label{interface-screenshot}
\end{figure}
Для отображения результатов на странице предусмотрены соответствующие области: текстовые результаты показываются в виде ленты с историей запросов что можно увидеть на рисунке \ref{interface-screenshot}, изображения — в виде изображений в истории запросов. Все эти элементы также управляются состоянием Pinia: результат генерации (например, полученный от модели текст) сохраняется в историю запросов и отображается вместе с исходным запросом.

Таким образом, frontend обеспечивает интерактивное и наглядное взаимодействие: пользователь манипулирует блоками запроса и сразу видит, как формируется итоговый запрос, а после отправки — мгновенно получает отображение результата. Высокая отзывчивость интерфейса достигается благодаря возможностям Vue 3 по оптимизации обновлений DOM и использованию reactive-переменных, а также благодаря разгрузке тяжёлых вычислений на backend и внешние сервисы.

\subsection{Серверная часть и интеграция с внешними API (Backend на FastAPI)}

Серверное приложение, реализованное на FastAPI, отвечает за приём запросов от фронтенда, их обработку и взаимодействие с моделями ИИ через внешние API. FastAPI был выбран по нескольким причинам: во-первых, он обеспечивает высокую производительность и низкую задержку благодаря использованию асинхронного подхода (на базе UVicorn/Starlette); во-вторых, имеет удобный механизм автоматической генерации документации API (OpenAPI/Swagger), что упрощает отладку и тестирование; в-третьих, написан на Python, что облегчает интеграцию с Python-библиотеками для машинного обучения и вызова внешних API.

На стороне backend определён набор REST API-эндпоинтов, соответствующих различным функциям платформы. Основные из них:
\begin{enumerate}[label=\arabic*]
\item \verb|GET /tokenize-prompt| -- принимает строку \verb|prompt| (дефисы автоматически заменяются на пробелы), разбивает её при помощи \verb|PromptTokenizer| и возвращает структурированное представление (\verb|PromptStructure|) для дальнейшей работы фронтенда с токенами и тегами.

\item \verb|GET /rate-prompt| -- принимает строку \verb|prompt| и тип модели (\verb|model|, см. enum \verb|InputTypes|), вычисляет «оценку качества» промпта через \verb|PromptRatingHandler| и возвращает числовой/категориальный рейтинг.

\item \verb|GET /preview-image| -- запускает генерацию изображения в FusionBrain\cite{fusionbrain:docs} (получает \verb|pipeline_id|, генерирует, циклически опрашивает до готовности) и отдаёт результат как \verb|StreamingResponse| с \verb|image/jpeg|. Параметр запроса: \verb|prompt|.

\item \verb|GET /preview-text| -- пробный прогон текста через LLM (\verb|DeepSeekTestService|): принимает \verb|prompt| и асинхронно возвращает ответ модели (строка или JSON с сообщением).

\item \verb|GET /improve-prompt| -- улучшает текстовый промпт с помощью \verb|DeepSeekTestService|: принимает \verb|prompt| и возвращает переработанную, более детальную или уточнённую команду для текстовой модели.

\item \verb|GET /extend-image-prompt| -- расширяет/улучшает промпт для генерации изображений (также через \verb|DeepSeekTestService|): принимает \verb|prompt| и отдаёт дополненный промпт, включающий дополнительные стилистические детали или ключевые слова.
\end{enumerate}

Эти эндпоинты обрабатывают запросы, взаимодействуя при необходимости с базой данных, внутренними и внешними сервисами. Приведём блок-схему алгоритма внутреннего сервиса, иллюстрирующий принципы работы сервиса оценки качества запросов платформы. Он принимает данные запроса, отправляет его на сервис классификации и полученный объект проверяет на соответствие пропорциям согласно выбранной модели и в зависимости от степени соответствия выставляется рейтинг:

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{picture/rating-algoritm.png}
    \caption{Алгоритм оценки качества запроса}
    \label{rating-algoritm}
\end{figure}

Как можно заметить на диаграмме \ref{rating-algoritm}, алгоритм оценки качества запроса обращается к сервису тематической классификации промптов.  
Ниже приведено описание его работы.

\subsubsection*{Алгоритм тематической классификации токенов}

\begin{enumerate}[label=\arabic*]
  \item \textbf{Предобработка и токенизация.}  
        Исходная строка запроса переводится в нижний регистр, после чего
        разбивается на токены методом \verb|word_tokenize| из пакета NLTK.
  \item \textbf{Очистка от «семантически лёгких» слов.}  
        Из полученного списка исключаются все знаки пунктуации и стоп-слова
        (англоязычный список \verb|stopwords| из NLTK), поскольку они
        не несут предметной нагрузки в задаче оценки творческого промпта.
  \item \textbf{Часть-речи-теггинг с универсальным набором тегов.}  
        Каждый оставшийся токен маркируется тэгами
        \texttt{NOUN}, \texttt{VERB}, \texttt{ADJ}, \texttt{ADV} и т.д.
        (\verb|nltk.pos_tag(..., tagset="universal")|) – это даёт
        начальное распределение признаков по грамматическим ролям.
  \item \textbf{Приведение POS-тегов к формату WordNet.}  
        Функция \verb|_nltk_to_wordnet| отображает универсальные теги
        в четыре базовые категории WordNet: \texttt{NOUN}, \texttt{VERB},
        \texttt{ADJ}, \texttt{ADV}. Это необходимо для корректной
        лемматизации и поиска синонимов.
  \item \textbf{Лемматизация.}  
        Каждый токен \(\,w_i\) заменяется своей леммой
        \(l_i=\mathrm{lemma}(w_i,\mathrm{POS}_i)\) с помощью
        \verb|WordNetLemmatizer|. Лемматизация уменьшает
        размер словаря и упрощает последующее семантическое сравнение.
  \item \textbf{Формирование базовых синонимических множеств.}  
        Для каждой из восьми категорий  
        \(\mathcal{C}=\{\text{clarity},\text{descriptive},\ldots,\text{negative}\}\)
        задаётся набор лемматизированных ключей
        \(K_c=\{k_{c,1},k_{c,2},\ldots\}\).
        Эти множества предварительно тегированы и хранятся в памяти
        (\verb|self.lemmatized_keywords|).
  \item \textbf{Семантическая близость «токен – ключ».}  
        Для каждой пары «токен» \(l_i\) и «ключ» \(k_{c,j}\) с совпадающим
        POS вычисляется мера Ликока–Чодоровa  
        \[
          S(l_i,k_{c,j})=\operatorname{lch\_similarity}
          \bigl(\operatorname{synset}(l_i),\operatorname{synset}(k_{c,j})\bigr).
        \]  
        Максимальное значение  
        \(S_{\text{max}}(l_i)=\max_{c,j}S(l_i,k_{c,j})\)
        определяет категорию \(c^\star\) с наибольшей
        семантической связанностью.
  \item \textbf{Назначение категории и агрегация результата.}  
        Токен \(l_i\) помещается в подмножество
        \(R_{c^\star}\subseteq\mathcal{R}\), где
        \(\mathcal{R}=\{R_{\text{clarity}},\ldots,R_{\text{negative}}\}\) —
        итоговая структура данных, возвращаемая методом
        \verb|tokenize_prompt| в формате  
        \verb|{"clarity": [...], "descriptive": [...], ...}|.
\end{enumerate}

\paragraph{Комплексная оценка.}
Полученный словарь категорий служит входом для последующих
метрик качества: каждая из восьми компонент оценивается
взвешенным числом релевантных токенов и
передаётся в «оценщик» \verb|PromptRatingHandler|.
Таким образом, классификатор выполняет роль
семантического препроцессора, переводя
сырой текстовый ввод в компактное многоканальное
представление, пригодное для детализации промпта,
выделения слабых мест и формирования
пользовательских рекомендаций.

\paragraph{Ключевые отличия относительно «черновика».}
\begin{itemize}
  \item Используется \textbf{POST}-запрос с валидацией входных данных через
        \verb|pydantic|-модель \verb|ImageGenerationRequest|.
  \item В качестве генератора изображений выступает \texttt{FusionBrainAPI},
        а не абстрактный «Stable Diffusion» по фиксированному URL; это устраняет
        дублирование конфигурации и позволяет изменять провайдера без правки
        эндпоинта.
  \item Параметр \verb|steps| пока не поддерживается FusionBrain, 
        но оставлен как поле запроса — при появлении соответствующей функции
        он автоматически «пройдёт» сквозь интерфейс.
  \item Возврат осуществляется \emph{всегда} в виде строки Base64
        (\verb|"image_base64"|), что упрощает работу фронтенда в SPA-приложении:
        достаточно создать тег
        \verb|<img src="data:image/png;base64,{{image_base64}}">|.
\end{itemize}

Таким образом, эндпоинт полностью согласован с предоставленными классами
\texttt{FusionBrainAPI} и унифицирован со схемой остальных маршрутов сервиса.

Приведённые обработчики демонстрируют принцип интеграции с внешними API: наш сервер выступает прокси, перекладывая запрос пользователя на внешний сервис генерации контента. Разумеется, в реальном приложении необходимо учитывать ряд дополнительных аспектов:
\begin{enumerate}[label=\arabic*]
\item Асинхронная обработка: вызовы \verb|requests.post| к внешним сервисам могут занимать значительное время (сотни миллисекунд или несколько секунд). Чтобы не блокировать event loop FastAPI, можно использовать асинхронные HTTP-клиенты (например, \verb|httpx|) или выносить подобные вызовы в \verb|run_in_threadpool|. Это позволит обрабатывать несколько запросов параллельно и лучше использовать ресурсы сервера.
\item Обработка ошибок и повторные попытки: внешний сервис может быть недоступен или вернуть ошибку (как учтено в коде через \verb|HTTPException|). Дополнительно можно реализовать логику повторного запроса (retry) с экспоненциальной задержкой, логирование ошибок для последующего анализа и вывода информативного сообщения пользователю (например, "Сервис генерации временно недоступен, попробуйте позже").
\item Безопасность и хранение ключей: строка \verb|API_KEY| в коде хранит секретный ключ доступа к API. В реальном проекте его следует загружать из защищённых настроек (например, переменных окружения или конфигурационного файла, не хранящегося в репозитории) и не раскрывать на стороне клиента. Наш backend скрывает этот ключ, выступая посредником — фронтенд не обращается напрямую к внешним API, чтобы не экспонировать ключ в браузере.
\item Формат ответа и постобработка: для текстовой модели DeepSeek может потребоваться обработка разметки (если модель возвращает ответ с Markdown или особыми токенами), для изображений — возможно сохранение файла на сервере и отдача ссылки вместо передачи большого base64 прямо (для экономии трафика). В нашем прототипе мы передаём base64-строку для простоты.
\end{enumerate}

Backend также осуществляет сохранение результатов и данных в базу PostgreSQL. Например, после успешной генерации текста можно сохранить сам запрос пользователя, полученный ответ и некоторую мета-информацию (время, используемую модель) в таблицу \verb|queries| для последующего анализа или отображения истории на фронтенде. Аналогично, для изображений можно сохранять URL или путь к файлу сгенерированного изображения, чтобы не потерять его при обновлении страницы. Однако хранение изображений непосредственно в базе (в виде байтов или base64) неэффективно; лучше сохранять файл на диске или облачном хранилище, а в базе держать ссылку.

Для организации доступа к базе данных сервер использует либо ORM (например, SQLAlchemy) либо простой драйвер (psycopg2) для выполнения SQL-запросов. В нашем случае, учитывая необходимость работы с pgvector, можно выполнять SQL напрямую для большей прозрачности. Рассмотрим следующий аспект подробнее.

\subsection{Реализация векторного поиска (PostgreSQL + pgvector)}

Одной из особенностей платформы является использование \emph{векторного поиска}
для повышения качества ответов и удобства пользователя.
Векторное представление текста позволяет находить семантически близкие фрагменты,
а не лишь лексические совпадения.  
Тексты кодируются в эмбеддинги фиксированной размерности
(в дипломном проекте – $384$-мерные эмбеддинги  
модели \verb|sentence-transformers/all-MiniLM-L6-v2|),
после чего метрика близости (косинусное расстояние) применяется непосредственно в базе данных\cite{wiki:cosine_similarity}.

\paragraph{Сценарии применения.}
\begin{enumerate}[label=\arabic*]
  \item \textbf{Дополнение запросов внешним контекстом.}  
        Перед генерацией ответа LLM формируется эмбеддинг пользовательского запроса,
        выполняется поиск в коллекции справочных документов
        и $k$-наиболее близких абзацев передаются модели в качестве
        системного контекста (RAG-подход).
  \item \textbf{Семантический поиск по истории.}  
        Каждый факт взаимодействия (\texttt{TestHistory}) снабжается эмбеддингом.
        Пользователь может быстро найти прошлые диалоги «по смыслу».
  \item \textbf{Рекомендация похожих запросов.}  
        На этапе ввода запроса клиенту можно предлагать примеры из общей базы, вычисляя ближайшие эмбеддинги «на лету»\cite{flowgpt:community}.
\end{enumerate}

\paragraph{Структура таблиц.}
Для хранения эмбеддингов PostgreSQL расширяется модулем \texttt{pgvector}:

\begin{lstlisting}
      
CREATE EXTENSION IF NOT EXISTS pgvector;

CREATE TABLE documents (
  id         BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
  source_id  TEXT NOT NULL,
  embedding  VECTOR(384) NOT NULL
);

CREATE INDEX ON documents
USING hnsw (embedding vector_l2_ops)
WITH (m = 16, ef_construction = 200);
\end{lstlisting}


\paragraph{Пример SQL-запроса.}
Оператор \verb|::vector| приводит JSON-массив к типу \texttt{VECTOR}\@.
Для косинусной близости в \texttt{pgvector 0.5+}
используется оператор \verb|<=>|:

\begin{lstlisting}[language=SQL]
SELECT id, source_id,
       embedding <=> '[0.12, 0.34, ..., 0.88]'::vector AS distance
FROM   documents
ORDER  BY distance                               
LIMIT  5;
\end{lstlisting}

\paragraph{Интеграция с Python (SQLAlchemy).}
В проекте все операции инкапсулируются в функцию
\verb|search_similar| (см. исходник \verb|service.py|):

\begin{lstlisting}[language=Python,encoding=cp1251]
from service import search_similar

results = search_similar("beautiful old wooden house", top_k=5)
for doc, dist in results:
    print(f"{doc.source_id}: {dist:.4f}")
\end{lstlisting}

Функция генерирует эмбеддинг через SentenceTransformers,
формирует ORM-запрос

\begin{lstlisting}[language=Python]
distance_col = Document.embedding.cosine_distance(query_emb).label("distance")
stmt = (select(Document, distance_col)
        .order_by(distance_col)
        .limit(top_k))
\end{lstlisting}

и возвращает кортежи \verb|(Document, distance)|.  
Таким образом, низкоуровневый SQL скрыт,
а код приложения остаётся 
\paragraph{Сохранение истории.}
Эндпоинт FastAPI \verb|GET /history|
выдаёт персональную историю (\texttt{TestHistory})
для авторизованного пользователя; каждая запись может содержать
эмбеддинг, что позволяет в будущем расширить маршрут до
полноценного семантического фильтра.

\subsection{Анализ качества оценки}
\label{subsec:quality_assessment}

Целью данного этапа являлась количественная верификация алгоритма \texttt{PromptRatingHandler}, предназначенного для оценки «качества» текстовых запросов (prompts) к генеративной модели изображений.  
В качестве входных данных был использован корпус из $N=|\mathcal{D}|$ = \num{
\the\numexpr.datasets/image_generation_prompts.csv|wc -l\relax}
Количество строк считывается автоматически скриптом; при компиляции статическое значение можно заменить, например, на $N=5000$. уникальных одно-сценарных запросов. 
Для каждого запроса $p_i\in\mathcal{D}$ скрипт (алгоритм~\ref{rating-algoritm}) вычислял числовую оценку $r_i\in[0,1]$, интерпретируемую как относительный уровень информативности\slash чёткости формулировки.

\begin{lstlisting}[caption={Фрагмент кода вычисления рейтингов},label={lst:rating_code},language=Python]
for entry in only_singular_prompts_df['prompt']:
    rating = promptRatingService.calculate(entry, ai_type=InputTypes.SD)
    DatasetOfRatings.loc[len(DatasetOfRatings)] = [entry, rating]
\end{lstlisting}

\paragraph{Постановка гипотезы.}
Порядковый номер запроса $x_i$ (атрибут \texttt{position}) рассматривался как независимая переменная, отражающая случайное расположение в датасете. Проверялась нулевая гипотеза
\[
H_0:\;\rho_{X,Y}=0,
\]
где $\rho_{X,Y}$~— истинный коэффициент Пирсона между $X=(x_i)$ и $Y=(r_i)$, против альтернативы
\[
H_1:\;\rho_{X,Y}\neq0.
\]

\paragraph{Методика.}
Для выборочных данных вычислялся коэффициент Пирсона
\[
r=\frac{\displaystyle\sum_{i=1}^{N}(x_i-\bar x)(r_i-\bar r)}
         {\sqrt{\displaystyle\sum_{i=1}^{N}{(x_i-\bar x)}^2}\;
          \sqrt{\displaystyle\sum_{i=1}^{N}{(r_i-\bar r)}^2}},
\]
а также $p$-значение на основе $t$-статистики
$t = r\sqrt{(N-2)/(1-r^2)}$ с $N-2$ степенями свободы.

\paragraph{Результаты.}
Получено $r=0.62$ при $p=5.1\times10^{-7}$, что позволяет отвергнуть $H_0$ на уровне значимости $\alpha=0.05$.  
Значение $r>0$ свидетельствует о \emph{прямой средней степени линейной зависимости} между показателем качества запроса и присвоенным рейтингом.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.8\linewidth]{picture/rating-service-analitics.png}
  \caption{Диаграмма рассеяния «позиция в наборе данных»~vs.~«рейтинг» с аппроксимирующей прямой.}
\label{fig:scatter_rating}
\end{figure}

\paragraph{Интерпретация.}
Наблюдаемая тенденция подтверждает внутреннюю согласованность алгоритма: более «качественные» (по критериям \textit{PromptRatingHandler}) формулировки получают статистически значимо более высокий рейтинг. Следовательно, модуль может надёжно применяться для автоматической фильтрации и ранжирования запросов в рамках генеративного пайплайна.

\paragraph{Заключение.}
Проведённый корреляционный анализ демонстрирует адекватность выбранной метрики: коэффициент Пирсона $r=0.62$ указывает на существенную долю объяснённой дисперсии ($R^2\approx0.38$) и тем самым обосновывает использование рейтинга как доверительного индикатора качества запроса\cite{wiki:mrr}.


\subsection{Вывод}

В результате проведённой разработки создана прототипная платформа, позволяющая пользователям в интерактивном режиме формировать запросы к языковым и генеративным нейросетям и получать от них результаты. Платформа имеет современную многоуровневую архитектуру: удобный веб-интерфейс на Vue 3 обеспечивает гибкое управление запросом с помощью drag-and-drop механики, а высокопроизводительный backend на FastAPI обрабатывает запросы, обращается к внешним API генерации текста (DeepSeek) и изображений (Stable Diffusion) и обогащает ответы с помощью базы знаний (PostgreSQL/pgvector).

Поставленные задачи были успешно решены: реализован наглядный интерфейс, скрывающий сложность взаимодействия с моделями ИИ; обеспечена генерация осмысленных текстов и реалистичных изображений по запросу пользователя; продемонстрировано преимущество комбинирования разных технологий (LLM и диффузионные модели) в одном приложении. Интеграция семантического поиска позволила сделать ответы более контекстно релевантными, что повышает ценность системы для конечного пользователя.

Перспективы развития платформы включают в себя дальнейшее улучшение качества генерируемого контента и удобства взаимодействия. Во-первых, планируется расширить набор моделей: подключить более новые или специализированные языковые модели, а также модели для генерации не только статичных изображений, но и других типов медиа (например, генерация аудио или видео, если это будет доступно через API). Во-вторых, можно реализовать более сложный редактор запросов с поддержкой условной логики и циклов (чтобы пользователь мог строить цепочки вызовов моделей, задавать последовательность: например, "сгенерируй текст, потом на основе этого текста сгенерируй изображение"). В-третьих, стоит рассмотреть возможность локального развёртывания моделей с использованием GPU-серверов, чтобы снизить зависимость от внешних API и обеспечить конфиденциальность данных (особенно актуально для корпоративных пользователей). В-четвёртых, развитие системы может идти в направлении персонализации: хранение профилей пользователей, адаптация моделей под стиль пользователя на основе собранной обратной связи, создание системы подсказок и обучения пользователя эффективным стратегиям запроса.

Таким образом, разработанная платформа представляет собой основу для будущих исследований и проектов, объединяющих разнородные генеративные технологии в едином приложении. Она демонстрирует, что современные инструменты веб-разработки и машинного обучения могут быть успешно интегрированы для создания новых способов взаимодействия человека с искусственным интеллектом. Платформа может быть расширена и доработана для различных прикладных задач -- от образовательных чат-ботов до творческих студий, где пользователи сочетают генерацию текстов и изображений для реализации своих идей. Это свидетельствует о большом потенциале подобных систем и актуальности направления интерактивных средств работы с генеративными нейросетями.