\section{Проектирование модели платформы для интерактивного формирования
запросов к языковым и генеративным нейросетям}
\label{sec:designing}
\subsection{Целевая аудитория}
Целевой аудиторией системы являются пользователи-разработчики и художники, которые будут работать с ней на равных правах (единый уровень доступа). Платформа спроектирована с учётом их потребностей: с одной стороны, она предоставляет гибкие инструменты для тонкой ручной настройки запросов, с другой – наглядный и интуитивно понятный интерфейс, упрощающий работу с текстовым описанием. В следующих разделах будут подробно рассмотрены назначение системы, характеристики пользователей, требования, обоснованные техническими требованиями.

\subsection{Назначение системы}
Основное назначение разработанной системы – обеспечить пользователям возможность эффективно формировать и улучшать запросы (промпты) для различных нейросетевых моделей генерации текста и изображений.
Платформа предназначена для поддержки полного цикла работы с промптом: от начального наброска идеи до получения удовлетворительного результата. Она предоставляет единое интерактивное пространство для проектирования промптов, позволяя объединить несколько функций, которые ранее требовали разрозненных инструментов.

С помощью данной системы пользователи могут создавать и редактировать текстовые описания запросов, итеративно их уточняя и детализируя. Интеллектуальные функции платформы позволяют автоматически дополнять введённый текст недостающими деталями и контекстом, что помогает менее опытным пользователям (например, художникам, не обладающим глубокими навыками работы с языковыми моделями) получить более богатые описания. Встроенный модуль оценки качества анализирует сформулированный запрос и выдает количественный показатель (в диапазоне 0–100), отражающий ориентировочное качество промпта. Это даёт возможность сразу увидеть, насколько хорошо запрос может быть воспринят нейросетью, и при необходимости внести правки до генерации результата. Кроме того, система обеспечивает преобразование формата запроса под требования конкретной целевой модели: например, адаптирует описание под синтаксис, предпочтительный для модели генерации изображений или, наоборот, для диалоговой языковой модели. Наконец, реализован режим предварительного просмотра, позволяющий по нажатию кнопки отправить текущий промпт в тестовом режиме модели и получить пример отклика – сгенерированный фрагмент текста либо эскиз изображения.

Таким образом, платформа выполняет роль песочницы для промптов: разработчики могут отладить запросы для своих AI-модулей, а художники – подобрать оптимальные описания для генерации иллюстраций. За счёт возможности быстро просматривать результат и оценку, существенно сокращается число итераций "вслепую". Пользователи могут корректировать промпт до тех пор, пока не будут удовлетворены оценкой и предпросмотром, и лишь затем использовать его на основной целевой модели (например, в продакшн-системе либо в стороннем сервисе генерации). В итоге применение платформы позволяет повысить качество конечного генерируемого контента – будь то текстовые ответы модели или создаваемые изображения – и сделать процесс разработки промптов более эффективным и предсказуемым.

\subsection{Характеристика пользователей}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{picture/Диплом use case.png}
    \caption{Вариантов использования платформы}
    \label{usecase}
\end{figure}
Как отмечалось, предполагаемые пользователи системы – это разработчики и художники, работающие с генеративными нейросетями. При проектировании платформы исходили из того, что эти две категории пользователей обладают разным опытом и целями, но обе нуждаются в удобном инструменте для создания хороших промптов. Уровень доступа в системе для них одинаковый (роль обычного пользователя), то есть все функции платформы доступны как разработчикам, так и представителям творческих профессий без каких-либо ограничений, что можно заметить на диаграмме \ref{usecase}.

Разработчики (инженеры, специалисты по машинному обучению, авторы чат-ботов и др.) используют платформу преимущественно для отладки и улучшения текстовых запросов к языковым моделям. Для них важны гибкость и точность: они оценивают промпт с точки зрения логики обработки моделью, предсказывают, приведёт ли данная формулировка к нужному ответу. Разработчики, как правило, технически подкованы, поэтому им удобен режим прямого текстового редактирования промпта, возможность вручную корректировать даже мелкие детали формулировки. Они оценят также числовой показатель качества – метрику, которая поможет количественно сравнить разные варианты запросов. В их рабочем процессе платформа вписывается как инструмент быстрого прототипирования промптов: вместо того чтобы многократно вызывать целевую модель и получать от неё ответы для сравнения, разработчик может в интерактивном режиме довести один запрос до оптимального состояния, глядя на предварительные ответы от тестовой модели и на рейтинг качества. Получив удовлетворяющий результат, он переносит этот промпт в своё основное приложение или сервис.

Художники и специалисты по визуальному контенту (например, иллюстраторы, дизайнеры, концепт-художники) используют систему в несколько ином ключе – для создания описаний, на основе которых модели типа Stable Diffusion или Kandinsky генерируют изображения. Их цель – добиться, чтобы сформулированный текст точно передавал задуманный визуальный образ и стиль. Многие художники не имеют глубоких технических знаний, поэтому для них критична простота и наглядность интерфейса. Платформа учитывает это, предоставляя интуитивно понятные средства: режим редактирования через перетаскивание токенов особенно полезен, так как позволяет им воспринимать промпт не как сплошной текст, а как набор отдельных элементов или слов, из которых складывается описание сцены. Перемещая эти элементы, художник может экспериментировать с композицией фразы, не задумываясь о синтаксисе – система автоматически обновит текст запроса. Функция автоматического дополнения детализацией полезна для художника тем, что нейросеть сама предложит дополнительные детали (например, обстановку, освещение, стилистические прилагательные), которые могут улучшить итоговое изображение. Предпросмотр через API Fusion Brain позволяет им практически мгновенно увидеть черновой результат: например, эскиз сгенерированного изображения по текущему описанию. Это визуальная обратная связь чрезвычайно ценна – художник сразу поймёт, в правильном ли направлении двигается, и при необходимости скорректирует промпт (добавит или уберёт детали, изменит формулировку).

Важно подчеркнуть, что система не вводит разграничений между разработчиками и художниками на уровне функционала. И те, и другие работают в одной среде с идентичными возможностями. Это решение принято исходя из многопрофильности современных команд: нередко разработчики и дизайнеры работают совместно над проектами с AI, и им удобно использовать единый инструмент. Платформа удовлетворяет потребности обоих типов пользователей: обеспечивает достаточно тонкий контроль для удовлетворения запросов разработчиков и одновременно остается дружественной для творческих специалистов, не требуя от них знаний программирования. Такой подход расширяет потенциальную аудиторию системы и повышает её ценность в междисциплинарных командах.

\subsection{Технические требования}

Разработка платформы базируется на предварительно сформулированных технических требованиях, отражающих необходимый функционал и ограничения системы. Требования охватывают как функциональные возможности, видимые пользователю, так и нефункциональные характеристики (производительность, совместимость, безопасность и др.). Ниже перечислены ключевые требования к системе.

Функциональные требования (основной пользовательский функционал платформы):

\begin{enumerate}[label=\arabic*]
    \item Редактирование запросов в текстовом и визуальном режиме. Система должна предоставлять интерфейс для ввода и правки текста промпта вручную (классическое текстовое поле) и альтернативный интерфейс в виде списка токенов, которые пользователь может перемещать, удалять или заменять. Любое изменение последовательности токенов в графическом режиме должно незамедлительно отражаться в текстовом представлении промпта, и наоборот, обеспечивая двунаправленную синхронизацию. Должна поддерживаться работа с промптом произвольной длины (в разумных пределах, например до 1000 символов) и с различными символами, включая буквы разных алфавитов, цифры, знаки препинания и эмодзи (это важно, так как некоторые модели допускают использование эмодзи в описании изображения)\cite{fusionbrain:docs}. Пользователь должен видеть текст своего запроса и иметь возможность редактировать его удобным для себя способом.
    \item Автоматизированное дополнение (расширение) запроса деталями. Платформа должна по запросу пользователя уметь генерировать расширенную версию введённого промпта, добавляя к нему недостающую детализацию. Фактически, это интеллектуальный помощник: на основе исходного чернового текста запроса система (с помощью внутренней языковой модели) предлагает дополнительные описательные фразы, контекст или уточнения, которые могут сделать запрос более понятным для нейросети. Например, пользователь ввёл краткий запрос "кот сидит на дереве", а система может предложить дополнить: "кот сидит на дереве в лучах заходящего солнца, вокруг осенний пейзаж". Метод вызова – нажатие специальной кнопки ("Дополнить"), после чего текущий текст промпта вместе с уже введёнными деталями остается, а к нему в конец или по соответствующим местам добавляется сгенерированный моделью текст (пользователь затем может отредактировать результат по своему усмотрению). Требуется, чтобы дополнение работало корректно для разных типов запросов (как описательных, так и вопросительных) и на двух основных языках (русский и английский), учитывая, что целевые модели поддерживают многоязычные запросы.
    \item Оценка качества промпта. В системе реализуется автоматическая оценка составленного пользователем запроса по шкале от 0 до 100. Эта оценка носит рекомендательный характер и должна отражать степень соответствия промпта лучшим практикам и ожидаемым требованиям модели. Пользователю отображается числовое значение или графический индикатор (например, цветовая индикация: красный – низкое качество, зелёный – высокое). Внутренне оценка может основываться на наборе правил или модели, анализирующих текст: учитывается длина запроса, специфичность формулировок, наличие деталей, отсутствие противоречий или запретов. Например, слишком короткий или расплывчатый запрос получит низкую оценку, а конкретный, содержательный запрос – более высокую. Чем более точно и понятно сформулирован промпт, тем выше должен быть рейтинг. (Это соответствует рекомендациям по промптингу: качество результатов зависит от того, сколько информации предоставлено и насколько хорошо запрос составлен)\cite{promptingguide:basics}. Данный модуль служит подсказкой: он должен быстро (в течение долей секунды) пересчитывать оценку при изменении текста и тем самым стимулировать пользователя улучшать запрос до получения приемлемого балла.
    \item Предварительный просмотр результата. Одним из важнейших требований является возможность быстрой генерации чернового результата по текущему запросу. Пользователь, не покидая интерфейс редактора промптов, должен получить от системы пример отклика целевой модели – сгенерированный текст или изображение, соответствующее введённому описанию. Данный функционал реализуется двумя способами: для текстовых моделей – через API DeepSeek, для изображений – через вызов внешнего API Fusion Brain. Платформа должна определить, какой тип результата требуется (например, по выбранному целевому движку или по контексту: если пользователь редактирует текстовый запрос для чат-бота, то генерируется текст-ответ; если промпт адресован модели изображения, то генерируется картинка). После нажатия кнопки "Предпросмотр" происходит обращение к соответствующей модели:
    \begin{enumerate}[label=4.\arabic*]
        \item В случае текста: DeepSeek генерирует продолжение или ответ на заданный промпт (необходимо ограничить размер выдаваемого фрагмента, например 1000 символов, чтобы получить быстрый предварительный ответ). Полученный ответ отображается на экране (например, в отдельном поле под запросом).
        \item В случае изображения: сервер отправляет запрос к API Fusion Brain (модель Kandinsky 3.1) с параметрами генерации (тип = GENERATE, текст запроса и др.). В ответ через некоторое время возвращается сгенерированное изображение, которое выводится пользователю (в виде эскиза, уменьшенного изображения либо полноразмерного, если позволяет интерфейс). Пользователь должен иметь возможность быстро увидеть этот результат в интерфейсе, без ручного перехода на внешние сервисы. Например, платформа может отобразить сгенерированную картинку прямо в браузере. В обоих случаях предварительно сгенерированный контент носит ознакомительный характер – он позволяет оценить, что примерно получится из данного промпта. Пользователь, проанализировав результат, может тут же подправить запрос и снова вызвать предпросмотр, добиваясь улучшения. Важно, чтобы среднее время получения предпросмотра было приемлемым: для текста это обычно менее 5 секунд, для изображения – порядка 5–15 секунд (зависит от мощности сервера и скорости внешнего API).
    \end{enumerate}
\end{enumerate}
Помимо основных функций, вытекают и общие технические требования к системе: 
\begin{enumerate}[label=\arabic*]
    \item Интуитивность и удобство интерфейса. Пользователи разных категорий должны легко освоить работу с платформой. Интерфейс должен быть локализован (минимум на русском языке, так как аудитория – в том числе русскоговорящие художники). Все элементы (кнопки "Оценить", "Предпросмотр", переключатель режима редактирования и т.д.) должны быть наглядно обозначены. Требуется реализация динамического обновления – например, пересчёт оценки качества без перезагрузки страницы, мгновенная синхронизация текстового и токенного представления запроса. Это подразумевает использование возможностей SPA (Vue.js) для реактивности.
    \item  Производительность и масштабируемость. Платформа должна эффективно работать при одновременном использовании несколькими пользователями. Ожидается, что число активных пользователей невелико (например, сотни или тысячи, поскольку целевая аудитория – команда разработчиков или художников или отдельные специалисты), однако архитектура не должна иметь жёстких ограничений на масштабирование. Серверная часть на FastAPI должна обрабатывать параллельно несколько запросов (благодаря асинхронности и производительности FastAPI это достижимо)\cite{fastapi:practicum}. Важно оптимизировать время отклика: интерактивные операции (редактирование, оценка) происходят почти мгновенно, а более тяжёлые (предпросмотр) – максимально быстро для выбранных моделей.  Для Fusion Brain API и DeepSeek API можно предусмотреть обработку в асинхронном режиме (не блокируя основной поток приложения во время ожидания ответа от внешнего сервиса).
    \item Ограничения и обработка ошибок. Система должна корректно обрабатывать нестандартные ситуации: слишком длинные запросы (превышающие лимиты модели) – выдавая предупреждение или автоматически укорачивая до допустимого размера; недопустимые символы – экранируя или удаляя их; отсутствие связи с внешним API – уведомляя пользователя о невозможности получить предпросмотр в данный момент. Все входные данные валидируются (FastAPI и Pydantic обеспечивают автоматическую проверку типов и форматов на уровне API\cite{yandex:fastapi}), а при обнаружении некорректных – сервер возвращает понятные сообщения об ошибках. Важным требованием является устойчивость: сбой одной из компонентов (например, недоступность БД или падение модели) не должен приводить к неуправляемому краху всего приложения – должны быть предусмотрены механизмы возврата в консистентное состояние или перезапуска сервиса.
    \item Совместимость и развиваемость. Платформа должна быть построена с использованием стандартных веб-технологий, обеспечивающих её совместимость с основными браузерами (Chrome, Firefox, Safari, Edge) без необходимости установки специальных плагинов. Желательно соблюдение принципов адаптивности интерфейса (возможность работать на экране ноутбука, настольного ПК, и, по возможности, на планшете). В архитектуре и коде должны быть заложены возможности расширения: например, добавление новых моделей (если в будущем понадобится поддержать другую нейросеть для генерации аудио или видео, или добавить ещё одну языковую модель) не должно требовать переписывания системы с нуля. Это означает, что компоненты (модуль оценки, модуль реструктуризации) должны быть реализованы конфигурируемо, с возможностью подключения новых правил или алгоритмов.
\end{enumerate}
Сформулированные выше требования служат основой для проектирования системы. На их основании в следующих разделах выбираются соответствующие методики и технические решения, обосновывается архитектура, алгоритмы работы и необходимые ресурсы. Соблюдение этих требований должно обеспечить, что итоговая платформа будет полнофункциональной, удобной для целевых пользователей и надёжной в эксплуатации.
\subsection{Требования к алгоритмическому и программному обеспечению}
В данном разделе описаны предполагаемые ключевые алгоритмы, реализующие функции платформы, а также программное обеспечение (библиотеки, фреймворки) и принятые технические решения, которые будут влиять на разработку приложения. Также рассматриваются программные средства, обеспечивающие выполнение этих алгоритмов.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth, height=100pt]{picture/diploma-inter-algo-1.png}
    \caption{Алгоритм редактирования запроса}
    \label{algo-1}
\end{figure}

Редактирование запросов (текст и токены). Алгоритм редактирования в текстовом режиме тривиален и отображён на диаграмме \ref{algo-1}: пользователь вводит или изменяет строку символов, которая хранится во внутреннем состоянии приложения. Более интересен алгоритм представления промпта в виде набора токенов. Здесь под токеном понимается либо отдельное слово, либо устойчивое словосочетание – на практике для упрощения можно принять токенизацию по пробелам и знакам пунктуации (каждое слово или знак рассматривается как отдельный элемент). При переключении в режим токенов исходный текст промпта разбивается на массив токенов. Этот массив отображается на экране, например, в виде последовательности интерактивных "карточек" с текстом. Для реализации перетаскивания используются возможности HTML5 DnD или готовые компоненты из экосистемы Vue (например, Vue.Draggable). Далее массив конкатенируется обратно в строку с добавлением пробелов – таким образом получается обновлённый текст промпта. Vue.js автоматически отследит изменение массива токенов и обновит связанную переменную текста (или наоборот, если связность сделана через одно хранилище состояния). Таким образом обеспечивается одновременная актуализация обоих представлений. Кроме того, если пользователь в текстовом поле ручным образом изменяет текст (например, дописывает новое слово), алгоритм распознаёт это (через реактивный watcher) и пересобирает список токенов заново. В результате редактирование может происходить параллельно в любом формате без рассинхронизации. Этот алгоритм достаточно прост (основные операции – разбиение строки и объединение списка), поэтому не нагружает систему даже при длинных промптах.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{picture/diploma-inter-algo-2.png}
    \caption{Алгоритм дополнения запроса}
    \label{algo-2}
\end{figure}
Дополнение запроса детализацией. Данная функция опирается на алгоритмы генерации текста с помощью модели DeepSeek. При нажатии пользователем кнопки "Дополнить" клиент отправляет текущий текст промпта на сервер (эндпойнт verb|/complete prompt|). Сервер вызывает специальную функцию, которая обращается к API модели DeepSeek. Алгоритм представлен на диаграмме \ref{algo-2} состоит из следующих шагов:
\begin{itemize}
    \item клиент отправляет исходный текст на сервер;
    \item сервер формирует входную подсказку (Prompt) для DeepSeek, используя шаблон <<Расширь описание \dots>;
    \item модель генерирует продолжение с учётом заданных параметров (длина, температура и пр.);
    \item полученные фразы автоматически добавляются к исходному промпту.

\end{itemize}

Алгоритмически, основная интеллектуальная работа здесь выполняется языковой моделью. Предусмотрены некоторые меры для улучшения результата: например, если модель начала повторять исходный текст или уводит в сторону, сервер может отсечь первые токены генерации до появления новых данных. Поскольку DeepSeek предоставляется готовым REST API, он интегрирована через Rest API.  Таким образом, алгоритм дополнения промпта сводится к задаче последовательного генерирования текста нейросетью – типичная задача, для которой используются наработки и функции библиотек машинного обучения.

Оценка качества промпта. Алгоритм оценки – это комбинация эвристических правил и, потенциально, моделей машинного обучения. В рамках данного проекта реализуется более простой, объяснимый подход на основе метрик текста. При вызове функции оценки (пользователь нажимает, либо автоматически при изменениях) клиент отправляет промпт на сервер (\verb|/evaluate\ prompt|). Сервер вызывает функцию evaluate prompt(text), которая выполняет следующие шаги:
\begin{enumerate}[label=\arabic*]
    \item Анализ длины и полноты. Вычисляется длина текста (в словах или символах). Если длина меньше некоторого порога (например, менее 3–5 слов), выставляется низкий базовый балл (такие запросы, как правило, слишком общие). Оптимальный диапазон длины – эмпирически, скажем, 10–20 слов для текстовых моделей, 5–15 слов для графических (со стилевыми тегами). Если запрос очень длинный (более 50–100 слов), тоже может снижаться балл – за избыточность.
    \item Проверка специфичности. Алгоритм может содержать список "пустых" слов (типа "изобрази", "сделай" – паразитные для промпта генерации изображения) и, наоборот, проверить наличие содержательных прилагательных, уточняющих фраз. Например, наличие хотя бы одного прилагательного или определяющего оборота может добавлять балл, так как уточняет запрос. В руководствах по промптингу подчёркивается, что специфичность и контекст повышают качество результата\cite{promptingguide:basics}. Следовательно, если промпт содержит детали (например, указание стиля, времени суток, эмоций персонажа и т.п.), это положительно влияет на оценку.
    \item Ясность формулировки. Проверяется, нет ли в тексте двусмысленностей или нерелевантных фрагментов. Этот пункт сложнее формализовать, но можно частично оценить по структуре предложения: если промпт состоит из нескольких несвязанных предложений или вопросительных форм (которые могут сбить модель), балл снижается. Например, запрос вида: "Нарисуй кота. Может дерево? Нет, лучше солнце." явно плох по структуре – алгоритм может обнаружить наличие нескольких предложений или вопросительных знаков и снизить оценку.
    \item Учет модели. Если уже выбрана целевая модель, алгоритм может использовать разные профили оценки. Например, для изображения ценятся указания на визуальный стиль (реалистичный, мультяшный, 3D-рендер и т.д.) – их наличие повышает балл. Для текста ценится чётко поставленный вопрос или задача – наличие вопросительного знака при обращении к чат-боту, наоборот, может быть положительным (для диалоговой модели).
    \item Формирование итогового балла. Балл вычисляется на основании нескольких компонент. Например: score = length score + specificity score + clarity score + model adaptation score. Каждая в диапазоне 0–25, суммируя до 100. Данный подход позволяет объяснить оценку: "Ваш промпт слишком короткий, добавьте деталей" – если низкий length score, "промпт содержит противоречивые указания" – если clarity score низкий, и т.п.
    \item Возврат балла. Сервер возвращает число от 0 до 100. Клиент отображает его, при этом возможно сопроводить коротким вердиктом (например, "Среднее качество" при 50–70, "Отличный промпт" при >80).
\end{enumerate}
Этот алгоритм легко модифицировать под новые критерии, его можно обучить (если бы были данные промптов с оценками, можно настроить веса правил или модель классификатор). Пока же он реализован на основе здравого смысла и рекомендаций по написанию промптов\cite{vc:prompt}, \cite{promptingguide:basics}. Программно реализация выполнена на Python: для лингвистического анализа можно использовать стандартные библиотеки (например, NLTK или simple pos-tagging для выделения частей речи, если нужно искать прилагательные). Однако в простейшем варианте достаточно операций над строками, что не требует внешних зависимостей. Важно отметить, что время выполнения этого алгоритма невелико – порядка нескольких миллисекунд, т.к. текст анализируется без тяжёлых моделей. Поэтому оценка может обновляться практически мгновенно при каждом изменении запроса.

Реструктуризация промпта под модель. Алгоритм реструктуризации заключается в применении определённого набора правил трансформации текста в зависимости от целевой модели. Эти правила основаны на известных требованиях и особенностях промптов для разных генераторов. Реализация может быть как шаблонной (набор if/else в коде), так и с участием нейросети. В первом прототипе достаточно правила:
\begin{enumerate}[label=\arabic*]
    \item Для модели изображения (Fusion Brain):\begin{enumerate}[label=1.\arabic*]
        \item Удалить обращение к модели в повелительном наклонении. Например, фразы вроде "нарисуй", "сгенерируй картинку:" не несут содержания для модели, их следует убрать.
        \item Выделить негативные указания. Если в тексте есть конструкции "не используй ...", "без ...", они преобразуются в отдельный негативный промпт (для Kandinsky предусмотрено поле negativePromptUnclip). Алгоритм: найти ключевые слова "не", "без", собрать последующие слова до запятой или конца – это будет отрицательный промпт.
        \item Проверить язык описания. Kandinsky 3.1 понимает и русский, и английский\cite{fusionbrain:docs}. Здесь не нужно перевода, но важно убедиться, что промпт цельный на одном языке (смешение языков нежелательно).
        \item Возможно, добавить стандартные атрибуты, если их нет: например, многие художники добавляют стилистические теги ("арт", "реалистично", "аниме-стиль"). Если пользователь ничего про стиль не указал, алгоритм мог бы по умолчанию добавить что-то нейтральное (но чаще стиль лучше оставить пустым – Fusion Brain и так принимает параметр style, который по умолчанию = NONE).
        \item Итогом алгоритма станет либо изменённая строка промпта, либо структура с полями: main\_prompt и negative\_prompt. Сервер знает, что для FusionBrain надо использовать оба. На стороне клиента это может отобразиться или остаться скрытым – по решению.
    \end{enumerate}
    \item Для языковой модели (DeepSeek или подобные): 
    \begin{enumerate}[label=2.\arabic*]
        \item Если исходный промпт больше походил на описание картинки (например, перечисление объектов без вопроса), а цель – текст, возможно, стоит преобразовать его в форму задания или вопроса. Например, промпт "кот сидит на дереве ночью" для чат-бота LLM непонятен – алгоритм мог бы добавить "Опиши сцену: кот сидит на дереве ночью." либо обернуть это в вопрос: "Что произошло: кот сидит на дереве ночью? Расскажи историю." Но такие преобразования могут оказаться слишком творческими. Вероятно, лучше минимально менять текст.
        \item Удалить специфические теги или слова, характерные для графических запросов (типа "4K", "highly detailed") – в текстовой модели они бессмысленны.
        \item Если целевая языковая модель – диалоговая, можно добавить, например, пометку "User: \{prompt\} Assistant:" для внутренних нужд (в LLaMA 2 есть формат входа с метками ролей).
    \end{enumerate}
\end{enumerate}
В целом алгоритм реструктуризации во многом состоит из поиска и замены. Он оперирует строкой: ищет определённые шаблоны (регулярные выражения или ключевые фразы) и преобразует их. Его сложность невысока, реализация на Python с библиотекой re или просто методами строк. При расширении на новые модели (например, аудиогенерация) нужно будет добавить соответствующие правила (например, убрать слова "изображение", заменить их на "звук", и т.д.).

Предварительный просмотр результата представлен, как последовательность показанную на диаграмме \ref{algo-3}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{picture/diploma-inter-algo-3.png}
    \caption{Алгоритм предпросмотра результата запроса}
    \label{algo-3}
\end{figure}


Данная последовательность заключается в следующих шагах:
\begin{itemize}
    \item пользователь нажимает кнопку "Предпросмотр";
    \item клиент отправляет запрос \texttt{/preview} с текстом и типом результата (текст/изображение);
    \item сервер корректирует промпт и определяет модель – DeepSeek или Fusion Brain;
    \item для текста генерируется ответ, для изображения – вызов API Kandinsky;
    \item полученные данные сервер возвращает в JSON или base64, затем клиент отображает предварительный результат;
    \item пользователь может повторить предпросмотр, внося корректировки в промпт.
\end{itemize}

Таким образом, набор описанных алгоритмов (редактирование, дополнение, оценка, реструктуризация, предпросмотр) в сочетании с перечисленными фреймворками и библиотеками обеспечивает требуемый функционал платформы.

\subsection{Конструктивно-технологические решения}
Разработка программного обеспечения всегда сопряжена с выбором не только алгоритмов, но и конкретных технологий, а также способов их интеграции и развертывания. В данном разделе рассматриваются решения, касающиеся архитектуры системы в техническом (конструктивном) плане и организационно-технологические аспекты: структура развёртывания компонентов, способ обеспечения их совместной работы, обоснование выбранных технологий с точки зрения инфраструктуры и будущей поддержки.

\par Логическая и физическая структура системы. Платформа разделена на несколько компонентов, как описано в архитектуре: клиент (Vue.js), сервер (FastAPI + модели) и база данных (PostgreSQL). Логически они взаимодействуют через чёткие интерфейсы (HTTP API, SQL). Физически для упрощения развертывания на практике они могут быть размещены на одном сервере или виртуальной машине, либо на нескольких, в зависимости от требований к производительности.
Для целей дипломного проекта предполагается локальное развертывание: на одной машине запускаются все нужные сервисы. Это упрощает демонстрацию и тестирование.

Использование контейнерных технологий. Для облегчения установки и переноса системы был выбран подход с применением Docker-контейнеров.
Контейнеризация обеспечивает единообразие среды (исключает проблему "у меня работает, у вас нет"), а также облегчает деплоймент на сервер. Компоненты запускаются оркестратором (например, Docker Compose прописывает три сервиса: web, api, db, и нужные сети между ними).

Выбор технологий и обоснование. Принятые технологические решения обусловлены требованиями к функционалу и ограничениями ресурсов:
FastAPI vs альтернативы: рассматривались Flask и Django. Flask слишком низкоуровневый и требует больше ручной работы по структуре проекта и валидации данных. Django избыточен (целый MVC-фреймворк) для задачи создания API. FastAPI же специально создан для API, поддерживает асинхронность и даёт высокую производительность на уровне, близком к Node.js или Go благодаря использованию Uvicorn или Starlette\cite{easyoffer:fastapi}. Кроме того, его встроенные механизмы (взаимодействие с Pydantic) упрощают безопасную обработку входных данных (что хорошо для безопасности – см. раздел 9) и автоматическое документирование. Достоинства FastAPI – высокая производительность и простота – стали решающими факторами\cite{fastapi:practicum}.

Одним из ключевых решений стало использовать облачную модель DeepSeek (например, \texttt{deepseek-llm-67b-chat}) вместо развёртывания локальной LLaMA 8B.

\begin{enumerate}[label=\arabic*]
  \item \textbf{Отсутствие аппаратных требований.} 
        Все вычисления выполняются на стороне DeepSeek, поэтому не нужны собственные GPU-ресурсы и связанная с ними инфраструктура.

  \item \textbf{Более высокое качество и регулярные обновления.} 
        DeepSeek-67B существенно крупнее 8-миллиардной LLaMA и постоянно дообучается командой провайдера, что повышает точность и надёжность ответов. 
        Новые возможности (function calling, регулировка \texttt{temperature}/\texttt{top-p}, встроенные системы фильтрации) становятся доступны без перекомпиляции сервиса.

  \item \textbf{Экономия времени разработки.} 
        Интеграция сводится к отправке HTTP-запросов; масштабирование нагрузки происходит автоматически на стороне API.

  \item \textbf{Компромиссы.} 
        Генерация требует соединения с интернетом, а значит — дополнительное внимание к конфиденциальности передаваемых данных. 
        Получить скрытые представления или выполнить тонкую дообучку "как в PyTorch" нельзя, но на практике большинство задач закрываются prompt-инженерией и настройками, предоставляемыми API.
\end{enumerate}

Таким образом, переход на DeepSeek снижает издержки на инфраструктуру и повышает среднее качество генераций, оставаясь приемлемым там, где допустима отправка запросов во внешний сервис \cite{deepseek:docs}.

Fusion Brain API vs локальная генерация изображений: Для генерации изображений был выбран готовый API (Fusion Brain, предоставляющий доступ к модели Kandinsky 3.1)\cite{sitelabs:kandinsky}. Альтернативой могло быть поднятие локального сервиса Stable Diffusion или самой модели Kandinsky. Однако это потребовало бы дополнительных больших вычислительных ресурсов (еще один крупный вес модели, отдельный GPU). С учётом ограничений оборудования и времени, было рациональнее воспользоваться внешним сервисом. Fusion Brain выбран, так как это российская платформа, свободно доступная для использования (модель Kandinsky бесплатна и поддерживает русский язык\cite{sitelabs:kandinsky}), что соответствует целевой аудитории. Также, Kandinsky 3.1 – одна из самых продвинутых моделей генерации изображений на момент разработки, демонстрирует высокое качество (почти на уровне MidJourney в ряде случаев). Использование её API позволяет пользователям получать высококачественные превью изображений без необходимости самим иметь мощный GPU. Таким образом, это решение – компромисс между качеством и сложностью: перенести нагрузку по генерации изображений на удалённый сервис. Конечно, от сервиса требуется интернет-соединение, но в современных условиях это приемлемо.Для клиента выбрана Vue.js из-за её более низкого порога вхождения и удобства для постепенного внедрения. Разработчики, особенно знакомые с HTML и CSS, обычно легче осваивают Vue, тогда как React требует писать больше шаблонного кода, а Angular – слишком громоздок для небольшого проекта. Vue известен своей доступностью и отличной документацией\cite{vuejs:wiki}. В итоге, Vue.js обеспечивает быструю разработку интерактивного интерфейса при небольших затратах времени. Для хранения данных выбрана PostgreSQL, хотя объем сохраняемой информации невелик. Обоснование – промышленная надежность и масштабируемость. PostgreSQL – открытая ORDBMS с более чем 30-летней историей разработки, одна из самых продвинутых БД с открытым кодом\cite{postgresql:skillfactory}, поддерживающая строгие гарантии сохранности данных. В случае расширения проекта (например, ведение большой базы промптов, статистики) PostgreSQL справится без проблем. Кроме того, использовать ее удобно в Docker-контейнере, а также многие ORM поддерживают ее "из коробки". SQLite могла бы быть проще на этапе прототипа, но для веб-приложения с потенциально несколькими пользователями параллельно SQLite не так надёжен (он однопоточный). Поэтому предпочтение отдано PostgreSQL – надежность данных и возможность роста.Организация разработки и деплоймента. При реализации данного проекта был использован подход непрерывной интеграции: код хранится в системе контроля версий (Git), настроено автоматическое построение Docker-образов при обновлении. Это облегчает тестирование на разных машинах (можно быстро развернуть весь стек с помощью docker-compose up). Также применялись практики разбиения задач: клиент и сервер разрабатывались отдельно, через согласованный API (для проверки использовались инструменты типа Swagger UI, сгенерированный FastAPI автоматически, что помогало разработчику клиента видеть, какие запросы доступны).

Безотказность и отказоустойчивость. Конструктивно, система спроектирована с учетом потенциальных отказов. Если падает внешний сервис (Fusion Brain), платформа всё ещё функционирует частично. Пользователю выдаётся сообщение об ошибке внешнего сервиса, но само приложение не "рушится".Если по какой-то причине недоступна модель DeepSeek (например, нет подключения к интернету или серверам сервиса), FastAPI возвращает код ошибки при попытке её использовать, а интерфейс может предупредить, что текстовый предпросмотр временно недоступен. При этом другие функции (хранение истории, редактирование) работают.База данных – единая точка хранения. В случае сбоя БД (например, отключилась) сервер не сможет записать или прочитать историю или выполнить логин. Такие ситуации обрабатываются: сервер выдаст ошибку 500, а на UI можно отобразить уведомление "Сервис временно недоступен". Чтобы повысить надежность, в продуктивной эксплуатации СУБД обычно запускают с механизмами репликации, регулярного бэкапа. Для дипломного прототипа достаточно периодически сохранять дамп БД и, при необходимости, перезапустить контейнер БД (данные не потеряются благодаря использованию volume для хранения файлов БД на хосте).

В итоге, принятые конструктивно-технологические решения – использование контейнеризации, разделение на компоненты, выбор оптимального стека – обеспечили надежную и гибкую основу для реализации платформы. Этот подход облегчает как текущую разработку (каждый компонент можно развернуть и отладить независимо), так и дальнейшее сопровождение (обновление отдельного сервиса не нарушит работу остальных при соблюдении контракта API). Все решения согласованы с требованиями: например, использование DeepSeek с необходимостью генерции и обработки текста, а привлечение Fusion Brain – с требованием высококачественного предпросмотра изображений. Такое сочетание решений подтверждает целесообразность и реализуемость проекта в заданных условиях.

\subsection{Безопасность и аутентификация}

При проектировании платформы уделяется серьёзное внимание вопросам безопасности – как защите данных пользователей, так и устойчивости системы к злонамеренным воздействиям. Также реализованы механизмы аутентификации, гарантирующие доступ к функционалу только авторизованным лицам (в рамках данного проекта – зарегистрированным пользователям с ролью разработчика или художника). Ниже описаны меры, принятые для обеспечения безопасности и процессы аутентификации пользователей.


\begin{figure}[h]
\centering
    \includegraphics[width=1\textwidth]{picture/diploma-deffence-algo-1.png}
\caption{Схема аутентификации пользователя}
\label{diagram_auth}
\end{figure}


Платформа использует систему учётных записей с безопасным хранением паролей (bcrypt) и выдачей JWT-токенов. Все запросы к защищённым эндпойнтам требуют валидного JWT, что гарантирует доступ только авторизованным пользователям. Общая схема аутентификации показана на рис.~\ref{diagram_auth}.


Разграничение доступа. На данный момент все аутентифицированные пользователи имеют одинаковые права (могут редактировать свои промпты, получать предпросмотр и т.д.). Однако система спроектирована с возможностью введения ролей. Например, можно добавить роль администратор, которому доступны дополнительные сведения (просмотр истории всех пользователей, управление учётными записями).  JWT содержит зашифрованные данные (id, роль), подписанные секретным ключом. При каждом запросе на сервер клиент прикрепляет токен в заголовке \texttt{Authorization}. Сервер валидацией подписи убеждается, что пользователь активен, и пускает к ресурсам согласно роли (рис.~\ref{diagram_jwt}).

Передача данных по сети. Взаимодействие клиент-сервер происходит по HTTP(S). Для безопасности в рабочей эксплуатации необходимо использовать протокол HTTPS с валидным SSL-сертификатом. Это гарантирует шифрование всего трафика: логинов, паролей, токенов, а также передаваемых промптов и сгенерированных результатов. Настройка HTTPS достигается либо за счёт reverse-proxy (например, Nginx с SSL передаёт на Uvicorn), либо используя встроенные возможности UVicorn + Hypercorn. Шифрование критически важно, чтобы злоумышленник в одной сети с пользователем не смог перехватить JWT или крадущим образом прочесть содержимое передаваемых промптов.

Защита API и данных. Внутри серверного кода внедрены следующие меры безопасности:
\begin{itemize}
    \item шифрование (HTTPS) защищает логины, пароли и промпты;
    \item валидация данных (Pydantic) и ORM предотвращают SQL-инъекции;
    \item ключи и конфигурация (например, API-ключи) хранятся только на сервере;
    \item длина промпта ограничена (до 1000 символов), чтобы избежать злоупотреблений;
    \item история запросов и конфиденциальные данные изолированы по user\_id.
\end{itemize}

Защита данных пользователя. Помимо паролей, которые хранятся в виде хешей, следует отметить и защиту содержимого истории промптов. Хотя они не столь конфиденциальны, все же это интеллектуальная собственность пользователя (особенно для художника: удачно сформулированный промпт – ценность). Поэтому история запросов каждого пользователя закрыта от других (как описано), а также от постороннего доступа извне (невозможно без JWT вытащить эти данные через API). При хранении на диске бэкапы БД также должны быть защищены (например, шифрованы или доступны только администратору).

\paragraph{Удалённая модель и передача данных.}
DeepSeek работает как сервис "модель-как-API": всё исполнение происходит на стороне провайдера.
Поэтому \emph{вычислительный код модели} не попадает в инфраструктуру, однако
\emph{данные запроса} (промпт и контекст) передаются по сети.  


\begin{figure}[htbp]
\centering
    \includegraphics[width=1\textwidth]{picture/diploma-deffence-algo-2.png}
\caption{Проверка и использование JWT-токена}
\label{diagram_jwt}
\end{figure}
Для их защиты следует:

\begin{itemize}
  \item использовать только зашифрованные соединения (\texttt{https});
  \item хранить ключ доступа (\texttt{DEEPSEEK\_API\_KEY}) в \texttt{.env} и передавать в заголовке \texttt{Authorization: Bearer};
  \item регулярно ротировать ключ и немедленно отзывать его при подозрении на компрометацию.
\end{itemize}

\paragraph{Prompt-injection и нежелательный контент.}
Даже будучи удалённой, модель остаётся уязвимой к \emph{prompt injection}: злоумышленник может сформулировать
вопрос так, чтобы обойти системные инструкции и получить приватные данные или токсичный текст.
Чтобы смягчить риск, применяются два уровня фильтрации:

\begin{enumerate}[label=\arabic*]
  \item \textbf{Фильтр провайдера.} DeepSeek имеет встроенную модерацию и блокирует ответы, нарушающие правила использования.
  \item \textbf{Локальная пост-обработка.}  На стороне сервера можно
        \begin{itemize}
          \item проверять результат на стоп-слова/регулярные выражения,
          \item прогонять его через open-source модель,
          \item при необходимости усекать длину или удалять чувствительные данные перед отправкой клиенту.
        \end{itemize}
\end{enumerate}

\paragraph{Обновления безопасности.}
Клиентское ПО (\texttt{requests}, SDK DeepSeek, FastAPI) и базовый контейнер
нужно регулярно обновлять, так как в них могут обнаруживаться уязвимости.
Использование Docker облегчает переход на новые безопасные образы ОС.
Кроме того, при смене \texttt{DEEPSEEK\_API\_KEY} старые JWT-токены автоматически устаревают,
что защищает от повторного использования скомпрометированных ключей.

Таким образом, при обращении к DeepSeek переносится вычислительная нагрузка
с локального GPU на облако, но должны уделить больше внимания защите канала связи,
управлению ключами и пост-фильтрации содержимого \cite{deepseek:docs}.

Безопасность инфраструктуры. Сервер, на котором размещается система, должен быть защищен: настроен файрвол (открыты только необходимые порты – 443 для HTTPS, 80 может редиректиться на 443, и, возможно, 22 для SSH админа). Доступ к серверу по SSH – только администратору с ключом, либо через VPN. PostgreSQL сервер, если отдельный, то либо локальный, либо за firewall – не в открытом интернет (или по крайней мере с ограничением по IP доступа до сервера приложения). Резервные копии БД следует хранить шифрованно, если хранятся вне сервера.

Подытоживая: аутентификация в системе реализована посредством логина/пароля с безопасным хранением (bcrypt-хеши) и выдачей JWT-токенов. Авторизация (проверка прав) – все основные маршруты требуют валидного токена, и пользователь имеет доступ только к своим данным. Безопасность данных и кодов обеспечивается на нескольких уровнях: шифрование канала (HTTPS), валидация входа, защита БД от инъекций, ограничение привилегий. Принятые меры соответствуют общепринятым практикам веб-безопасности (OWASP) и учитывают особенности платформы (включая интеграцию ML). Таким образом, система защищена от большинства распространённых угроз: утечки учётных данных, несанкционированного доступа к данным, перехвата трафика, SQL-инъекций, brute-force атак на пароли и др. Это создаёт прочную основу доверия для пользователей: они могут безопасно использовать платформу, не опасаясь за сохранность своих персональных данных и уникальных промптов.
\subsection{Вывод}
В разделе проектирования была разработана подробная архитектура и техническое решение для платформы интерактивного формирования, оценки и предварительного просмотра запросов (промптов) к языковым и генеративным нейросетям. Платформа построена по принципу клиент-сервер и включает серверное приложение на FastAPI, взаимодействующее с внешними API Fusion Brain (модель Kandinsky 3.1) и DeepSeek для генерации изображений и текста, веб-клиент на Vue.js для удобного интерфейса и базу данных PostgreSQL для хранения пользовательских данных.

На основании требований были спроектированы конкретные методики реализации всех заявленных функций: редактирование промптов как в текстовом режиме, так и путём перетаскивания токенов; автоматизированное дополнение описаний с использованием возможностей большой языковой модели; вычисление метрики качества промпта по набору правил; преобразование формата запросов под требования разных моделей; механизм предпросмотра, позволяющий быстро получать отклики от модели (текстовые – через DeepSeek, графические – через FusionBrain) и показывать их пользователю. Каждый из этих функциональных блоков был рассмотрен с точки зрения алгоритмов и программных средств, что показало реализуемость поставленных задач.

Разработанная архитектура системы демонстрирует преимущества использования облачных сервисов: генерация изображений и текста делегирована специализированному удалённому сервису для достижения высокого качества без чрезмерных требований к оборудованию. Клиентское приложение на Vue.js обеспечивает интерактивность и отзывчивый интерфейс, удовлетворяющий потребностям как технических, так и творческих пользователей.

В ходе проектирования были приняты обоснованные схемотехнические, алгоритмические, программные и конструктивно-технологические решения. Выбор FastAPI и PyTorch на сервере обеспечил высокую производительность и гибкость при интеграции ML-модели, выбор Vue.js на клиенте – удобство реализации сложного UI. Внедрение JWT-аутентификации, bcrypt-хеширования паролей и других мер безопасности позволило создать надежный механизм защиты данных, что немаловажно для приложения, работающего с пользовательским контентом.

Проектирование учитывало профиль пользователей системы (разработчики и художники) – в решениях особое внимание уделено удобству интерфейса (двойной режим редактирования, визуальный просмотр результатов), а также обеспечению того, чтобы ни одна из групп не была технически ограничена в использовании платформы. Все требования заказчика по функционалу удовлетворены предлагаемым дизайном: система позволяет интерактивно экспериментировать с промптами, улучшать их качество и сразу видеть, к чему эти улучшения приводят, что в конечном итоге повышает эффективность работы с нейросетевыми моделями.
